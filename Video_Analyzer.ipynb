{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Video Analyzer with Code"
      ],
      "metadata": {
        "id": "cPQmUJxIwN-E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dIoTCuy2IxD4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "030e7826-c1c4-4912-c8ca-8453e66a779d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/118.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m112.6/118.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -U -q google-genai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Vhs2YlLIxl5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-JHsBtiI1GP"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "icUQh_qfKAtq"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Markdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3N49skOEKtKC"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"gemini-2.0-flash-exp\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qXiBDkvLceK"
      },
      "source": [
        "## Upload Our Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydu5sDbeQ0hq"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "\n",
        "# Use Path instead of path\n",
        "img_path = pathlib.Path('/content/drive/MyDrive/videoplayback.m4a')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbhuLaY8SFCQ"
      },
      "outputs": [],
      "source": [
        "#Upload the file using the API\n",
        "file_upload = client.files.upload(path=img_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLtZRSdTnoCT",
        "outputId": "1cf3da7b-6082-4fe2-afcb-fe76a9124981"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "File(name='files/t43xlkldxvpy', display_name=None, mime_type='audio/mp4', size_bytes=7585312, create_time=datetime.datetime(2025, 1, 8, 11, 54, 31, 165191, tzinfo=TzInfo(UTC)), expiration_time=datetime.datetime(2025, 1, 10, 11, 54, 31, 136698, tzinfo=TzInfo(UTC)), update_time=datetime.datetime(2025, 1, 8, 11, 54, 31, 165191, tzinfo=TzInfo(UTC)), sha256_hash=b'77c5df1135c1c7a45f29b5b858751d80f78513276ca0d2e79aeeb3554e4bff12', uri='https://generativelanguage.googleapis.com/v1beta/files/t43xlkldxvpy', state='ACTIVE', video_metadata=None, error=None)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "file_upload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "lPAEgb6qohH7",
        "outputId": "ca04743a-23e7-4676-a99a-302c8ee05a16"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ACTIVE'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "file_upload.state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tge38l76ov70"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "#prepare the file to be uploded\n",
        "while file_upload.state == \"PROCESSING\":\n",
        "  print(\"Waiting for video to be processed.\")\n",
        "  time.sleep(10)\n",
        "  file_upload = client.files.get(name=file_upload.name)\n",
        "\n",
        "if file_upload.state == \"FAILED\":\n",
        "  raise ValueError(file_upload.state)\n",
        "  print(f'video processing complete:' + file_upload.uri)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTfjtOAPqJBU",
        "outputId": "ddb02e83-bdcf-4175-acb7-c763ab434884"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ACTIVE\n"
          ]
        }
      ],
      "source": [
        "print(file_upload.state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yTJCtjtufud"
      },
      "source": [
        "## Basic Calling a prompt on the video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FmaKWyn0uTT-"
      },
      "outputs": [],
      "source": [
        "SYSTEM_PROMPT = \"When given a video and a query, call the relevant function only once with the appropriate timecodes and text for the video \""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRyKoMtTvnHj"
      },
      "outputs": [],
      "source": [
        "USER_PROPMT = \"For each scene in this video, generate captions that describe the scene along with any spoken text placed in quotation marks. Place each caption into an object sent to set_timecodes with the timecode of the caption in the video. \""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6xI80LPwb_9"
      },
      "outputs": [],
      "source": [
        "USER_PROPMT = \"For each scene in this video, generate captions that describe the scene along with any spoken text placed in quotation marks. Place each caption into an object with the timecode of the caption in the video\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GYjUMrC6xq3e",
        "outputId": "695c5a65-544e-47ab-b5cb-be79b7f5a028"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```json\n[\n  {\n    \"timecode\": \"0:00\",\n    \"text\": \"A person is speaking in front of a screen showing code. \\\"When we talked with Replit about how they built their agent, one of the things that they highlighted was the importance of human in the loop.\\\"\"\n  },\n  {\n    \"timecode\": \"0:10\",\n    \"text\": \"The screen shows a conversation between a user and an agent. \\\"And so you can see here on the side that they're showing a conversation of what's happening, but they're also letting the user approve the plan.\\\"\"\n  },\n  {\n    \"timecode\": \"0:19\",\n    \"text\": \"The speaker continues to talk about human in the loop interactions. \\\"And so this human in the loop interaction pattern is something that we've seen become really important and really common when building complex agent applications.\\\"\"\n  },\n  {\n    \"timecode\": \"0:29\",\n    \"text\": \"The speaker talks about LangGraph. \\\"And we've made LangGraph really, really good for these human in the loop interactions. And today we're adding a new tool called interrupt to make it even easier.\\\"\"\n  },\n  {\n    \"timecode\": \"0:39\",\n    \"text\": \"The speaker talks about the persistence layer of LangGraph. \\\"So let's take a look at that. To maybe set the stage a bit, the reason that LangGraph is so well built for human in the loop interaction patterns is the persistence layer that it's built on.\\\"\"\n  },\n  {\n    \"timecode\": \"0:49\",\n    \"text\": \"The speaker explains how the persistence layer works. \\\"So when you use LangGraph, if you pass in a checkpointer, then what happens is that between each step, the state of the graph is read from the checkpoint and then written to the checkpoint when it ends.\\\"\"\n  },\n  {\n    \"timecode\": \"1:01\",\n    \"text\": \"The speaker explains how the persistence layer allows for stopping and resuming execution. \\\"This means that you can stop execution anywhere and you can then resume an arbitrary time length later because you have that checkpoint. You have that exact state of the graph at that period of time.\\\"\"\n  },\n  {\n    \"timecode\": \"1:11\",\n    \"text\": \"The speaker explains how the persistence layer allows for editing. \\\"It also means that the human can edit that checkpoint, update it, add some different values, and then restart the graph from that new updated edited checkpoint.\\\"\"\n  },\n  {\n    \"timecode\": \"1:22\",\n    \"text\": \"The speaker describes the persistence layer as a scratchpad. \\\"You can think of it almost as a scratchpad for human agent collaboration.\\\"\"\n  },\n  {\n    \"timecode\": \"1:27\",\n    \"text\": \"The speaker explains that the persistence layer is a core part of LangGraph. \\\"So for everything that I'm going to talk about, this is enabled by the persistence layer that's a core part of LangGraph and has been from the beginning.\\\"\"\n  },\n  {\n    \"timecode\": \"1:34\",\n    \"text\": \"The speaker introduces the interrupt function. \\\"The new functionality we're adding is this interrupt function.\\\"\"\n  },\n  {\n    \"timecode\": \"1:39\",\n    \"text\": \"The speaker explains how the interrupt function is similar to the input function in Python. \\\"This function's kind of similar to the input function in Python.\\\"\"\n  },\n  {\n    \"timecode\": \"1:45\",\n    \"text\": \"The speaker explains how to use the interrupt function. \\\"So what it means is that inside a node, you can use interrupt and you can pass in any data into interrupt.\\\"\"\n  },\n  {\n    \"timecode\": \"1:52\",\n    \"text\": \"The speaker explains how the interrupt function saves data. \\\"That'll be saved as part of the persistence layer and the node will be interrupted right there.\\\"\"\n  },\n  {\n    \"timecode\": \"1:58\",\n    \"text\": \"The speaker explains how to resume the graph. \\\"You can then reinvoke the graph, and I'll show how to do that in a bit. And when you get back the result, that'll be written as this value. This is very similar to how input works in Python.\\\"\"\n  },\n  {\n    \"timecode\": \"2:09\",\n    \"text\": \"The speaker explains the difference between input and interrupt. \\\"The main difference is that while input is really useful for when you're running a graph in memory, in the CLI, in a notebook, it doesn't really work in production at all. Interrupt does.\\\"\"\n  },\n  {\n    \"timecode\": \"2:20\",\n    \"text\": \"The speaker explains how to use interrupt in a graph. \\\"So once you have this node where you're using interrupt, you can then build your graph. Notice that you will need to pass in a checkpointer because this relies on that persistence layer. You can invoke it the first time, pass in anything, and then it will eventually interrupt it there.\\\"\"\n  },\n  {\n    \"timecode\": \"2:36\",\n    \"text\": \"The speaker explains how to resume the graph with a command. \\\"And then you can resume by passing in this command thing with the value that you want to be written to this value. So, let's take a look at this in a little bit more detail and see it in action.\\\"\"\n  },\n  {\n    \"timecode\": \"2:47\",\n    \"text\": \"The speaker introduces a simple graph example. \\\"Let's take a look at a really simple graph here that shows off how to use interrupt.\\\"\"\n  },\n  {\n    \"timecode\": \"2:52\",\n    \"text\": \"The speaker explains the code for the simple graph. \\\"So I'm using the state graph, I'm using messages state. I only have one node. It's this human node. What I'm going to do inside this node is I'm going to use interrupt.\\\"\"\n  },\n  {\n    \"timecode\": \"3:01\",\n    \"text\": \"The speaker explains how the interrupt function is used in the node. \\\"Into interrupt, I'm going to pass this string. The string is going to be formatted with the messages that are in the state up to that point in time. I'm going to get back this value from interrupt and I'm going to update the state based on that value. So I'm going to make this an AI message.\\\"\"\n  },\n  {\n    \"timecode\": \"3:16\",\n    \"text\": \"The speaker explains how the graph is built. \\\"I'm going to build this graph, I'm going to use my checkpointer, it's an in memory checkpointer. I'm going to create this graph, I'm going to add a node, it's this only node, I'm going to set it as the entry point, going to build it, going to create this thread config, and then I'm going to invoke it with the initial messages. So role user, content hi.\\\"\"\n  },\n  {\n    \"timecode\": \"3:33\",\n    \"text\": \"The speaker explains how to get the state of the graph. \\\"Great. Let's now get the state of the graph at this point in time.\\\"\"\n  },\n  {\n    \"timecode\": \"3:38\",\n    \"text\": \"The speaker shows the state of the graph. \\\"We can see that so far, the state values are just a single message. It's just a human message, it's what I passed in.\\\"\"\n  },\n  {\n    \"timecode\": \"3:46\",\n    \"text\": \"The speaker shows the tasks on the state. \\\"We can see that there are a few tasks on the state. Well, there's one task on the state. And this task has some interrupts, one interrupt. And this interrupt is the value that I passed in earlier. What should I say in response to? And then this is this is the state that I that I formatted into the string.\\\"\"\n  },\n  {\n    \"timecode\": \"4:02\",\n    \"text\": \"The speaker explains how the interrupt is used. \\\"So this shows that this thread at this point in time is interrupted. And in that interrupt, I have information about why it's interrupted. And so you can put anything in this interrupt value that helps communicate to the end user why it is interrupted and how they should respond.\\\"\"\n  },\n  {\n    \"timecode\": \"4:18\",\n    \"text\": \"The speaker explains how to respond to the interrupt. \\\"And here is what it looks like to respond. So, I'm going to respond with the command tool, and we introduced this a few days ago. I'm going to pass in resume, and then how how is it going? This is going to be the value that will get saved right there.\\\"\"\n  },\n  {\n    \"timecode\": \"4:33\",\n    \"text\": \"The speaker shows the result of the resume command. \\\"So I'm going to pass that in, and then the graph is going to finish, and I can see that it added here this AI message with the content how's it going? This is what I passed in. This is what gets saved to value, and in turn, this is what updated the state.\\\"\"\n  },\n  {\n    \"timecode\": \"4:46\",\n    \"text\": \"The speaker summarizes the example. \\\"So this is a really simple example of how interrupt works in practice.\\\"\"\n  },\n  {\n    \"timecode\": \"4:50\",\n    \"text\": \"The speaker introduces common use cases for interrupt. \\\"Let's now talk about some common use cases for this.\\\"\"\n  },\n  {\n    \"timecode\": \"4:54\",\n    \"text\": \"The speaker explains the first use case, approve or reject. \\\"So first is kind of like an approve or reject step. The LLM makes some decision, this can either just be a response or it can be a function call, and the human approves it. If it approves it, then it goes to some node, or it rejects it. If it rejects it, it goes to a different node. This is a pretty common pattern.\\\"\"\n  },\n  {\n    \"timecode\": \"5:11\",\n    \"text\": \"The speaker explains the second use case, reviewing and editing the state. \\\"Another one is reviewing and editing the state. This is a little bit more involved. So now you have the state of the graph, and so it could be the response of an LLM or it could be documents or it could be anything. And the human's going to go in, they're going to review that whole state, and then they're going to pass in some information that's going to update that state optionally, and then after that's done, it will go to the next node.\\\"\"\n  },\n  {\n    \"timecode\": \"5:31\",\n    \"text\": \"The speaker explains how this use case is useful. \\\"So this is useful for correcting mistakes.\\\"\"\n  },\n  {\n    \"timecode\": \"5:34\",\n    \"text\": \"The speaker explains how this use case is useful. \\\"So this can be useful for correcting mistakes or updating the state with additional information.\\\"\"\n  },\n  {\n    \"timecode\": \"5:40\",\n    \"text\": \"The speaker explains the third use case, reviewing tool calls. \\\"This is kind of similar to the previous use case of approve or reject, but just calling it out that reviewing tool calls is one of the main use cases for human in the loop that we see.\\\"\"\n  },\n  {\n    \"timecode\": \"5:49\",\n    \"text\": \"The speaker explains how reviewing tool calls is useful. \\\"So the LLM may generate a tool call or multiple tool calls with multiple arguments, and having the human in the loop to decide whether that tool call is correct and whether it should be executed can be really, really important, particularly in critical applications where that tool call is requested by the LLM may be sensitive or require human oversight.\\\"\"\n  },\n  {\n    \"timecode\": \"6:10\",\n    \"text\": \"The speaker explains the fourth use case, multi-turn conversations. \\\"Finally, this can be a useful design pattern for when you're building multi-turn conversations in multi-agent setups.\\\"\"\n  },\n  {\n    \"timecode\": \"6:17\",\n    \"text\": \"The speaker explains how to use the persistence layer for single agent conversations. \\\"So if you're doing a multi-turn conversation with a single agent, then you can just use the persistence layer as normal and use the memory that way.\\\"\"\n  },\n  {\n    \"timecode\": \"6:24\",\n    \"text\": \"The speaker explains how to use interrupt for multi-agent conversations. \\\"When you're doing a multi-turn conversation with multiple agents, then it's often nice to have a human node and just interrupt there rather than finishing the graph run, because then after that human node, you know exactly where you are in any of the three or four, however many agents you have, and you can return to that agent after you respond rather than having to do some routing at the beginning.\\\"\"\n  },\n  {\n    \"timecode\": \"6:44\",\n    \"text\": \"The speaker explains that the human in the loop can be done by the end user or a third party. \\\"Note that for all of these use cases, the human in the loop interaction pattern can be done either by the end user or by a third party who's kind of like reviewing and monitoring the system. So there's a lot of optionality here.\\\"\"\n  },\n  {\n    \"timecode\": \"6:58\",\n    \"text\": \"The speaker summarizes the importance of human in the loop. \\\"We think human in the loop design patterns are crucial for building reliable and useful agents. We want LangGraph to be the best place to build these types of human in the loop agents. So please check this out and let us know if you have any feedback. Thanks for watching.\\\"\"\n  }\n]\n```"
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        types.Content(\n",
        "           role=\"user\",\n",
        "            parts=[\n",
        "                types.Part.from_uri(\n",
        "                    file_uri=file_upload.uri,\n",
        "                    mime_type=file_upload.mime_type),\n",
        "                ]),\n",
        "        USER_PROPMT,\n",
        "    ],\n",
        "   config=types.GenerateContentConfig(\n",
        "       system_instruction=SYSTEM_PROMPT,\n",
        "       temperature=0.0,\n",
        "   ),\n",
        ")\n",
        "\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MkqcEWn9r3O"
      },
      "source": [
        "## Add in the Function Calls to get back the data in a way we expect it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBovHv8w6_vP"
      },
      "outputs": [],
      "source": [
        "set_timecodes = types.FunctionDeclaration(\n",
        "    name=\"set_timecodes\",\n",
        "    description=\"Set the timecodes for the video associated text\",\n",
        "    parameters={\n",
        "        \"type\": \"OBJECT\",\n",
        "        \"properties\": {\n",
        "            \"timecodes\": {\n",
        "                \"type\": \"ARRAY\",\n",
        "                \"items\": {\n",
        "                    \"type\" : \"OBJECT\",\n",
        "                    \"properties\" : {\n",
        "                        \"time\": {\"type\": \"STRING\"},\n",
        "                        \"text\": {\"type\": \"STRING\" },\n",
        "                    },\n",
        "                    \"required\": [\"time\", \"text\"],\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "        \"required\": [\"timecodes\"]\n",
        "    }\n",
        ")\n",
        "\n",
        "set_timecodes_with_objects = types.FunctionDeclaration(\n",
        "    name=\"set_timecodes_with_objects\",\n",
        "    description=\"Set the timecodes for the video with associated text and object list\",\n",
        "    parameters={\n",
        "        \"type\": \"OBJECT\",\n",
        "        \"properties\": {\n",
        "            \"timecodes\": {\n",
        "                \"type\": \"ARRAY\",\n",
        "                \"items\": {\n",
        "                    \"type\" : \"OBJECT\",\n",
        "                    \"properties\" : {\n",
        "                        \"time\": {\"type\": \"STRING\"},\n",
        "                        \"text\": {\"type\": \"STRING\" },\n",
        "                        \"object\":{\n",
        "                            \"type\": \"ARRAY\",\n",
        "                            \"items\":{\"type\":\"STRING\"},\n",
        "                        },\n",
        "                        },\n",
        "                       \"required\": [\"time\", \"text\", \"object\"],\n",
        "           }\n",
        "        }\n",
        "    },\n",
        "        \"required\": [\"timecodes\"],\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "set_timecodes_with_numeric_values =  types.FunctionDeclaration(\n",
        "    name=\"set_timecodes_with_numeric_values\",\n",
        "    description=\"Set the timecodes for the video with associated numeric values\",\n",
        "    parameters={\n",
        "        \"type\": \"OBJECT\",\n",
        "        \"properties\": {\n",
        "            \"timecodes\": {\n",
        "                \"type\": \"ARRAY\",\n",
        "                \"items\": {\n",
        "                    \"type\" : \"OBJECT\",\n",
        "                    \"properties\" : {\n",
        "                        \"time\": {\"type\": \"STRING\"},\n",
        "                        \"value\": {\"type\": \"NUMBER\" },\n",
        "                        },\n",
        "                       \"required\": [\"time\", \"value\"],\n",
        "                    }\n",
        "        }\n",
        "    },\n",
        "        \"required\": [\"timecodes\"],\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "set_timecodes_with_description = types.FunctionDeclaration(\n",
        "    name=\"set_timecodes_with_descriptions\",\n",
        "    description=\"Set the timecodes for the video with associated spoken text and visual descriptions\",\n",
        "    parameters={\n",
        "        \"type\": \"OBJECT\",\n",
        "        \"properties\": {\n",
        "            \"timecodes\": {\n",
        "                \"type\": \"ARRAY\",\n",
        "                \"items\": {\n",
        "                    \"type\" : \"OBJECT\",\n",
        "                    \"properties\" : {\n",
        "                        \"time\": {\"type\": \"STRING\"},\n",
        "                        \"spoken_text\": {\"type\": \"STRING\" },\n",
        "                        \"visual_description\": {\"type\": \"STRING\"},\n",
        "                    },\n",
        "                    \"required\": [\"time\", \"spoken_text\", \"visual_description\"],\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "        \"required\": [\"timecodes\"]\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3mSvbYBEuJR"
      },
      "outputs": [],
      "source": [
        "video_tools = types.Tool(\n",
        "    function_declarations=[set_timecodes, set_timecodes_with_objects, set_timecodes_with_numeric_values],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-pL5jxaFPG3"
      },
      "outputs": [],
      "source": [
        "def set_timecodes_func(timecodes):\n",
        "  return [{**t, \"text\": t[\"text\"].replace(\"\\\\\",\"'\")} for t in timecodes]\n",
        "def set_timecodes_with_objects_func(timecodes):\n",
        "  return [{**t, \"text\": t[\"text\"].replace(\"\\\\\",\"'\")} for t in timecodes]\n",
        "def set_timecodes_with_description_func(timecodes):\n",
        "  return [{**t, \"text\": t[\"spoken_text\"].replace(\"\\\\\",\"'\")} for t in timecodes]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "Gnd46JKHl-lM",
        "outputId": "6968b4e1-91d4-4e3f-f5b2-ed2f9c3c197d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'For each scene in this video, generate captions that describe the scene along with any spoken text placed in quotation marks. Place each caption into an object with the timecode of the caption in the video'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "USER_PROPMT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TvsdRkGoj3q",
        "outputId": "3031aa73-0141-451b-8914-897d548b5828"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FunctionCall(id=None, args={'timecodes': [{'text': 'The video begins with a person speaking about Replit and their agent.', 'time': '0:00'}, {'text': 'The speaker highlights the importance of human in the loop and shows a conversation where the user approves the plan.', 'time': '0:06'}, {'text': 'The speaker says that human in the loop interaction is important when building complex agent applications.', 'time': '0:18'}, {'text': 'The speaker introduces a new tool called interrupt to make human in the loop interactions easier.', 'time': '0:27'}, {'text': 'The speaker explains that LangGraph is well built for human in the loop interactions because of the persistence layer.', 'time': '0:34'}, {'time': '0:45', 'text': 'The speaker explains that when using LangGraph, the state of the graph is read from the checkpoint and written to the checkpoint when it ends.'}, {'time': '0:53', 'text': 'The speaker explains that you can stop execution anywhere and resume later because of the checkpoint.'}, {'text': 'The speaker explains that the human can edit the checkpoint, update it, and restart the graph from the new checkpoint.', 'time': '1:00'}, {'time': '1:08', 'text': 'The speaker says that the checkpoint is like a scratchpad for human agent collaboration.'}, {'text': 'The speaker says that the new functionality they are adding is the interrupt function.', 'time': '1:15'}, {'text': 'The speaker says that the interrupt function is similar to the input function in Python.', 'time': '1:20'}, {'time': '1:27', 'text': 'The speaker explains that inside a node, you can use interrupt and pass in any data.'}, {'text': 'The speaker explains that the data will be saved as part of the persistence layer and the node will be interrupted.', 'time': '1:33'}, {'text': 'The speaker explains that you can reinvoke the graph and the result will be written as a value.', 'time': '1:39'}, {'time': '1:47', 'text': \"The speaker says that the main difference between input and interrupt is that input doesn't work in production, but interrupt does.\"}, {'text': 'The speaker explains that you need to pass in a checkpoint when using interrupt.', 'time': '1:55'}, {'text': 'The speaker explains that you can invoke the graph the first time and it will eventually interrupt it.', 'time': '2:00'}, {'text': 'The speaker explains that you can resume by passing in a command with the value that you want to be written.', 'time': '2:07'}, {'text': 'The speaker shows a simple graph that shows how to use interrupt.', 'time': '2:15'}, {'text': 'The speaker explains that they are using a state graph with a single human node.', 'time': '2:20'}, {'text': 'The speaker explains that inside the node, they are using interrupt and passing in a string formatted with the messages in the state.', 'time': '2:26'}, {'text': 'The speaker explains that they will get back a value from interrupt and update the state based on that value.', 'time': '2:34'}, {'text': 'The speaker explains that they are building the graph, using an in memory checkpoint, and adding the node as the entry point.', 'time': '2:40'}, {'text': 'The speaker explains that they are invoking the graph with initial messages.', 'time': '2:49'}, {'text': 'The speaker shows the state of the graph at this point in time.', 'time': '2:54'}, {'time': '3:00', 'text': 'The speaker shows that there is one task on the state with one interrupt.'}, {'text': 'The speaker explains that the interrupt has the value that was passed in earlier.', 'time': '3:06'}, {'text': 'The speaker explains that the thread is interrupted and the interrupt has information about why it is interrupted.', 'time': '3:12'}, {'time': '3:19', 'text': 'The speaker explains that you can put anything in the interrupt value to communicate to the end user why it is interrupted and how they should respond.'}, {'text': 'The speaker shows how to respond with the command tool and resume.', 'time': '3:27'}, {'time': '3:34', 'text': 'The speaker explains that the value passed in will be saved and the graph will finish.'}, {'time': '3:40', 'text': 'The speaker shows that the AI message was added with the content that was passed in.'}, {'time': '3:45', 'text': 'The speaker says that this is a simple example of how interrupt works.'}, {'text': 'The speaker begins to talk about common use cases for interrupt.', 'time': '3:49'}, {'text': 'The speaker says that one use case is an approve or reject step.', 'time': '3:53'}, {'time': '3:58', 'text': 'The speaker explains that the LLM makes a decision and the human approves or rejects it.'}, {'time': '4:05', 'text': 'The speaker says that another use case is reviewing and editing the state.'}, {'time': '4:10', 'text': 'The speaker explains that the human reviews the state and passes in information to update it.'}, {'time': '4:19', 'text': 'The speaker says that this is useful for correcting mistakes or updating the state with additional information.'}, {'text': 'The speaker says that reviewing tool calls is one of the main use cases for human in the loop.', 'time': '4:24'}, {'time': '4:29', 'text': 'The speaker explains that the LLM may generate a tool call and the human can decide if it is correct and should be executed.'}, {'text': 'The speaker says that this is important in critical applications where the tool call may be sensitive.', 'time': '4:38'}, {'time': '4:44', 'text': 'The speaker says that this can be a useful design pattern for multi-turn conversations in multi-agent setups.'}, {'text': 'The speaker explains that when doing a multi-turn conversation with a single agent, you can use the persistence layer as normal.', 'time': '4:50'}, {'text': 'The speaker explains that when doing a multi-turn conversation with multiple agents, it is nice to have a human node and interrupt there.', 'time': '4:56'}, {'text': 'The speaker says that for all of these use cases, the human in the loop interaction can be done by the end user or a third party.', 'time': '5:08'}, {'time': '5:16', 'text': 'The speaker says that human in the loop design patterns are crucial for building reliable and useful agents.'}, {'time': '5:21', 'text': 'The speaker says that they want LangGraph to be the best place to build these types of agents.'}, {'text': 'The speaker asks the viewer to check it out and let them know if they have any feedback.', 'time': '5:26'}, {'time': '5:29', 'text': 'The video ends.'}]}, name='set_timecodes')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        types.Content(\n",
        "           role=\"user\",\n",
        "            parts=[\n",
        "                types.Part.from_uri(\n",
        "                    file_uri=file_upload.uri,\n",
        "                    mime_type=file_upload.mime_type),\n",
        "                ]),\n",
        "        USER_PROPMT,\n",
        "    ],\n",
        "   config=types.GenerateContentConfig(\n",
        "       system_instruction=SYSTEM_PROMPT,\n",
        "       tools=[video_tools],\n",
        "       temperature=0,\n",
        "   ),\n",
        ")\n",
        "\n",
        "response.candidates[0].content.parts[0].function_call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kVLmuxMphOd",
        "outputId": "1dc0ffdc-94d0-4aed-bcad-aa1f2f34a1fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "Markdown(response.candidates[0].content.parts[0].text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBdjsFk6rjzv"
      },
      "outputs": [],
      "source": [
        "USER_PROPMT = \"For each scene in this video, generate captions that describe the scene along with any spoken text placed in quotation marks. place each caption into an object sent to set_timecodes with the timecode of the caption in the video. \""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqv6_v-ntnsU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9514b1ad-4cc8-4cb3-84d6-c8e481c027d1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FunctionCall(id=None, args={'timecodes': [{'time': '0:00', 'text': 'The video begins with a person speaking about Replit and their agent.'}, {'text': 'The speaker highlights the importance of human in the loop and shows a conversation where the user approves the plan.', 'time': '0:06'}, {'text': 'The speaker mentions that human in the loop interaction is important when building complex agent applications.', 'time': '0:18'}, {'text': \"The speaker introduces a new tool called 'interrupt' to make human in the loop interactions easier.\", 'time': '0:27'}, {'text': 'The speaker explains that LangGraph is well-built for human in the loop interactions due to its persistence layer.', 'time': '0:33'}, {'time': '0:45', 'text': 'The speaker explains that when using LangGraph, the state of the graph is read from and written to a checkpoint between each step.'}, {'time': '0:58', 'text': 'The speaker explains that the human can edit the checkpoint, update it, and restart the graph from the updated checkpoint.'}, {'text': 'The speaker says that the persistence layer is a core part of LangGraph.', 'time': '1:10'}, {'time': '1:15', 'text': \"The speaker introduces the new 'interrupt' function, which is similar to the input function in Python.\"}, {'text': 'The speaker explains that inside a node, you can use interrupt and pass in any data, which will be saved as part of the persistence layer.', 'time': '1:24'}, {'time': '1:34', 'text': 'The speaker explains that the node will be interrupted, and you can reinvoke the graph and get back the result as a value.'}, {'text': 'The speaker explains that while input is useful for running a graph in memory, interrupt works in production.', 'time': '1:44'}, {'time': '1:53', 'text': 'The speaker explains that you need to pass in a checkpoint when using interrupt, and you can invoke it the first time and it will eventually interrupt.'}, {'text': 'The speaker explains that you can resume by passing in a command with the value you want to be written.', 'time': '2:05'}, {'text': 'The speaker shows a simple graph that uses interrupt.', 'time': '2:12'}, {'time': '2:18', 'text': 'The speaker explains that the graph has one node, a human node, where interrupt is used.'}, {'text': 'The speaker explains that the interrupt is passed a string formatted with the messages in the state, and the value from interrupt is used to update the state.', 'time': '2:25'}, {'time': '2:38', 'text': 'The speaker builds the graph, uses an in-memory checkpoint, and invokes it with initial messages.'}, {'time': '2:50', 'text': 'The speaker gets the state of the graph, which shows a single human message.'}, {'text': 'The speaker shows that there is one task on the state with an interrupt, which is the value passed in earlier.', 'time': '2:57'}, {'text': 'The speaker explains that the thread is interrupted and the interrupt value helps communicate to the end user why it is interrupted and how to respond.', 'time': '3:09'}, {'text': 'The speaker shows how to respond with the command tool, passing in resume and a value.', 'time': '3:20'}, {'time': '3:29', 'text': 'The speaker shows that the graph finishes and adds an AI message with the content passed in.'}, {'time': '3:36', 'text': 'The speaker says this is a simple example of how interrupt works.'}, {'text': 'The speaker begins to talk about common use cases for interrupt.', 'time': '3:40'}, {'time': '3:45', 'text': 'The speaker explains the first use case, an approve or reject step, where the human approves or rejects an LLM decision.'}, {'text': 'The speaker explains the second use case, reviewing and editing the state, where the human reviews and updates the state.', 'time': '3:57'}, {'text': 'The speaker says this is useful for correcting mistakes or updating the state with additional information.', 'time': '4:10'}, {'time': '4:16', 'text': 'The speaker explains that reviewing tool calls is a main use case for human in the loop, where the human decides if a tool call is correct.'}, {'text': 'The speaker says this is important in critical applications where tool calls may be sensitive or require human oversight.', 'time': '4:29'}, {'text': 'The speaker explains that interrupt can be a useful design pattern for multi-turn conversations in multi-agent setups.', 'time': '4:37'}, {'text': \"The speaker explains that in multi-turn conversations with multiple agents, it's nice to have a human node and interrupt there.\", 'time': '4:48'}, {'time': '5:02', 'text': 'The speaker notes that human in the loop interaction can be done by the end user or a third party.'}, {'time': '5:10', 'text': 'The speaker says that human in the loop design patterns are crucial for building reliable and useful agents.'}, {'time': '5:16', 'text': 'The speaker says they want LangGraph to be the best place to build these types of agents and asks for feedback.'}, {'text': 'The video ends.', 'time': '5:23'}]}, name='set_timecodes')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=[\n",
        "        types.Content(\n",
        "           role=\"user\",\n",
        "            parts=[\n",
        "                types.Part.from_uri(\n",
        "                    file_uri=file_upload.uri,\n",
        "                    mime_type=file_upload.mime_type),\n",
        "                ]),\n",
        "        USER_PROPMT,\n",
        "    ],\n",
        "   config=types.GenerateContentConfig(\n",
        "       system_instruction=SYSTEM_PROMPT,\n",
        "       tools=[video_tools],\n",
        "       temperature=0,\n",
        "   ),\n",
        ")\n",
        "\n",
        "response.candidates[0].content.parts[0].function_call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6IYF1t5Vub6p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "d0bb0455-6064-4dc6-a4fc-ad283b35fd01"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'set_timecodes'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "response.candidates[0].content.parts[0].function_call.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHoxzy6RuuXT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6ca0d54-932c-4950-d1fc-9c855d1f99b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'time': '0:00',\n",
              "  'text': 'The video begins with a person speaking about Replit and their agent.'},\n",
              " {'text': 'The speaker highlights the importance of human in the loop and shows a conversation where the user approves the plan.',\n",
              "  'time': '0:06'},\n",
              " {'text': 'The speaker mentions that human in the loop interaction is important when building complex agent applications.',\n",
              "  'time': '0:18'},\n",
              " {'text': \"The speaker introduces a new tool called 'interrupt' to make human in the loop interactions easier.\",\n",
              "  'time': '0:27'},\n",
              " {'text': 'The speaker explains that LangGraph is well-built for human in the loop interactions due to its persistence layer.',\n",
              "  'time': '0:33'},\n",
              " {'time': '0:45',\n",
              "  'text': 'The speaker explains that when using LangGraph, the state of the graph is read from and written to a checkpoint between each step.'},\n",
              " {'time': '0:58',\n",
              "  'text': 'The speaker explains that the human can edit the checkpoint, update it, and restart the graph from the updated checkpoint.'},\n",
              " {'text': 'The speaker says that the persistence layer is a core part of LangGraph.',\n",
              "  'time': '1:10'},\n",
              " {'time': '1:15',\n",
              "  'text': \"The speaker introduces the new 'interrupt' function, which is similar to the input function in Python.\"},\n",
              " {'text': 'The speaker explains that inside a node, you can use interrupt and pass in any data, which will be saved as part of the persistence layer.',\n",
              "  'time': '1:24'},\n",
              " {'time': '1:34',\n",
              "  'text': 'The speaker explains that the node will be interrupted, and you can reinvoke the graph and get back the result as a value.'},\n",
              " {'text': 'The speaker explains that while input is useful for running a graph in memory, interrupt works in production.',\n",
              "  'time': '1:44'},\n",
              " {'time': '1:53',\n",
              "  'text': 'The speaker explains that you need to pass in a checkpoint when using interrupt, and you can invoke it the first time and it will eventually interrupt.'},\n",
              " {'text': 'The speaker explains that you can resume by passing in a command with the value you want to be written.',\n",
              "  'time': '2:05'},\n",
              " {'text': 'The speaker shows a simple graph that uses interrupt.',\n",
              "  'time': '2:12'},\n",
              " {'time': '2:18',\n",
              "  'text': 'The speaker explains that the graph has one node, a human node, where interrupt is used.'},\n",
              " {'text': 'The speaker explains that the interrupt is passed a string formatted with the messages in the state, and the value from interrupt is used to update the state.',\n",
              "  'time': '2:25'},\n",
              " {'time': '2:38',\n",
              "  'text': 'The speaker builds the graph, uses an in-memory checkpoint, and invokes it with initial messages.'},\n",
              " {'time': '2:50',\n",
              "  'text': 'The speaker gets the state of the graph, which shows a single human message.'},\n",
              " {'text': 'The speaker shows that there is one task on the state with an interrupt, which is the value passed in earlier.',\n",
              "  'time': '2:57'},\n",
              " {'text': 'The speaker explains that the thread is interrupted and the interrupt value helps communicate to the end user why it is interrupted and how to respond.',\n",
              "  'time': '3:09'},\n",
              " {'text': 'The speaker shows how to respond with the command tool, passing in resume and a value.',\n",
              "  'time': '3:20'},\n",
              " {'time': '3:29',\n",
              "  'text': 'The speaker shows that the graph finishes and adds an AI message with the content passed in.'},\n",
              " {'time': '3:36',\n",
              "  'text': 'The speaker says this is a simple example of how interrupt works.'},\n",
              " {'text': 'The speaker begins to talk about common use cases for interrupt.',\n",
              "  'time': '3:40'},\n",
              " {'time': '3:45',\n",
              "  'text': 'The speaker explains the first use case, an approve or reject step, where the human approves or rejects an LLM decision.'},\n",
              " {'text': 'The speaker explains the second use case, reviewing and editing the state, where the human reviews and updates the state.',\n",
              "  'time': '3:57'},\n",
              " {'text': 'The speaker says this is useful for correcting mistakes or updating the state with additional information.',\n",
              "  'time': '4:10'},\n",
              " {'time': '4:16',\n",
              "  'text': 'The speaker explains that reviewing tool calls is a main use case for human in the loop, where the human decides if a tool call is correct.'},\n",
              " {'text': 'The speaker says this is important in critical applications where tool calls may be sensitive or require human oversight.',\n",
              "  'time': '4:29'},\n",
              " {'text': 'The speaker explains that interrupt can be a useful design pattern for multi-turn conversations in multi-agent setups.',\n",
              "  'time': '4:37'},\n",
              " {'text': \"The speaker explains that in multi-turn conversations with multiple agents, it's nice to have a human node and interrupt there.\",\n",
              "  'time': '4:48'},\n",
              " {'time': '5:02',\n",
              "  'text': 'The speaker notes that human in the loop interaction can be done by the end user or a third party.'},\n",
              " {'time': '5:10',\n",
              "  'text': 'The speaker says that human in the loop design patterns are crucial for building reliable and useful agents.'},\n",
              " {'time': '5:16',\n",
              "  'text': 'The speaker says they want LangGraph to be the best place to build these types of agents and asks for feedback.'},\n",
              " {'text': 'The video ends.', 'time': '5:23'}]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "set_timecodes_func(response.candidates[0].content.parts[0].function_call.args['timecodes'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wiQwEN2L2jhy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}